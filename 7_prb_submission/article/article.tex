%\documentclass[aps,prb,amsmath,twocolumn,amssymb,titlepage]{revtex4-1}
\documentclass[10pt]{revtex4-1}
\usepackage{graphicx}
\usepackage{nicefrac}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath} 
\usepackage{subfigure}
\usepackage{multirow} 
\usepackage{tabularx} 
\usepackage{array}
\usepackage{units}
\usepackage{tensor} 
\usepackage{braket}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[resetlabels, labeled]{multibib}
%\newcites{supp}{References}

\renewcommand{\Re}{\operatorname{{\mathrm Re}}}
\renewcommand{\Im}{\operatorname{{\mathrm Im}}}
\newcommand{\tr}{\operatorname{{\mathrm tr}}} 

\newcommand{\hc}{^{\dagger}}
\newcommand{\ad}{\operatorname{{\mathrm ad}}}
\newcommand{\adn}{\ad_{\hat n}}
\newcommand{\adx}{\ad_{\hat x}}
\newcommand{\adX}[1][]{\ad_{\hat {\mathbf{X}}_{#1}}}
\newcommand{\adp}{\ad_{\hat p}}
\newcommand{\calD}{\mathcal{D}}    %Caligraphic D
\newcommand{\inbk}[1]{\left[ #1 \right]}
\newcommand{\inbr}[1]{\left\{ #1 \right\}}
\newcommand{\inp}[1]{\left( #1 \right)}
\newcommand{\pd}{\partial}
\newcommand{\pdf}[3]{\frac{\pd^{#1} #2}{\pd #3^{#1}}} %Partial derivative
\newcommand{\fdf}[3][]{\frac{\delta^{#1} #2}{\delta #3^{#1}}} %Functional
                                %derivative 

\begin{document}
\nocite{*}

\title{Machine learning topological phases in real space}

\author{N. L. Holanda}
\email{linneuholanda@gmail.com, linneu@cbpf.br}
\affiliation{Cavendish Laboratory, University of Cambridge, J. J. Thomson Avenue, Cambridge, CB3 0HE, United Kingdom}
\affiliation{Centro Brasileiro de Pesquisas F\'isicas, \\Rua Dr. Xavier Sigaud, 150 - Urca, 22290-180,  Rio de Janeiro, RJ, Brazil}

\author{M. A. S. Griffith}
\email{griffithphys@gmail.com}
\affiliation{Centro Brasileiro de Pesquisas F\'isicas, \\Rua Dr. Xavier Sigaud, 150 - Urca, 22290-180,  Rio de Janeiro, RJ, Brazil}
\affiliation{Departamento de Ci\^{e}ncias Naturais, Universidade Federal de S\~ao Jo\~ao Del Rei, Pra√ßa Dom Helv\'ecio 74, 36301-160, S\~ao Jo\~ao Del Rei, MG, Brazil}

\date{\today }

\begin{abstract}
We develop a supervised machine learning algorithm that is able to learn topological phases for finite condensed matter systems from bulk data in real lattice space. The algorithm employs diagonalization in real space together with any supervised learning algorithm to learn topological phases through an eigenvector ensembling procedure. We combine our algorithm with decision trees and random forests to successfully recover topological phase diagrams of Su-Schrieffer-Heeger (SSH) models from bulk lattice data in real space and show how the Shannon information entropy of ensembles of lattice eigenvectors can be used to retrieve a signal detailing how topological information is distributed in the bulk. The discovery of Shannon information entropy signals associated with topological phase transitions from the analysis of data from several thousand SSH systems illustrates how model explainability in machine learning can advance the research of exotic quantum materials with properties that may power future technological applications such as qubit engineering for quantum computing. 
\end{abstract}

\maketitle

\section*{Introduction}

The quest for innovative materials that harness exotic quantum properties has lured physicists into the realm of topological insulators and topological states of matter \cite{RevModPhys.82.3045}. These materials feature previously unthought-of traits like bulk insulation coupled with metallic conductance at the surface and the splitting of currents according to spin orientation. Adding to that, these properties are protected by non-trivial topology that renders them robust to many sources of perturbation like thermal noise. Such characteristics make them promising candidates to being the cornerstone of 21st century technologies like spintronics and quantum computing.

These new topological states of matter have been studied in several contexts in condensed matter physics including superconductors \cite {CONTINENTINO2017A1}$^-$\cite{ryu2010topological}, ultracold atoms \cite{atala2013direct}$^-$\cite{meier2016observation}, photonic crystals \cite{hafezi2013imaging}$^-$\cite{peng2016experimental}, photonic quantum walks \cite{kitagawa2012observation}$^-$\cite{PhysRevX.7.031023} and Weyl semimetals \cite{soluyanov2015type,PhysRevX.5.031013}. Among these, the Su-Schrieffer-Heeger (SSH) model \cite{PhysRevLett.42.1698} has attracted particular theoretical interest due to its simplicity and generality.

The SSH model is the simplest tight-binding model that exhibits a topological phase transition. As such, it can be viewed as the \emph{Drosophila} of the field, providing a simple framework for testing new techniques. The model can be expressed in terms of creation and annihilation operators by the Hamiltonian
\begin{equation}
\label{SSH_ham}
\hat{H}(\mathbf{t})=\mathbf{c}^{\dagger}H(\mathbf{t})\mathbf{c}
\end{equation}
and describes e.g. the hopping of electrons along a one-dimensional chain comprising two atoms per unit cell (a brief discussion of the SSH model and its topological properties can be found in the section \textbf{The SSH model} in the Supplementary Material). The SSH model has found several interesting applications in the modelling of diverse systems with non-trivial topology like optical lattices \cite{maffei2018topological}, polymeric materials \cite{RevModPhys.73.681} and topological mechanisms \cite{kane2014topological,Chen13004}.

Many recent papers have explored the possibility of treating the general problem of determining phase transition boundaries of physical systems as machine learning tasks \cite{carrasquilla2017machine}$^-$\cite{rodriguez2018identifying}. In the particular case of topological phase transitions, the usual approach for supervised learning is to generate a data set $\big(H_1(k), W_1\big)$, ..., $\big(H_n(k), W_n\big)$ whose inputs are representations of Hamiltonians in wavevector space $H_i(k)$ and targets are their corresponding topological invariants $W_i$ (for the SSH model the topological invariant is the winding number). Our paper extends this task to the case of learning topological phase diagrams from input data in real space. Strikingly, we find that information localized on a few lattice sites in the bulk is sufficient to predict with high accuracy which topological phase a particular Hamiltonian belongs to.

To investigate topological phases of matter in real space we have designed a novel supervised learning algorithm (here called eigenvector ensembling algorithm) tailored for the task of learning phase transition boundaries from local features. The algorithm is based on eigenvector decomposition and eigenvector ensembling and therefore will require minimal changes to be applicable to a broader class of data-driven physics problems. We demonstrate its effectiveness by combining it with decision trees and random forests to recover the topological phase diagrams of SSH systems from local coordinates of eigenstates in real space.

The advantage of using decision tree-based algorithms to learn topological phases from local eigenvector data is that their use of entropy-based cost functions (such as Shannon information entropy or Gini impurity) furnishes them with an intrinsinc model explanaibility tool that summarizes how important each feature was to learn the desired pattern in the data. This makes it much easier to trace the localization of relevant information along the features of a data set. Here we use the Shannon information entropy of ensembles of real space eigenvectors to recover a signal quantifying the amount of topological information available from each lattice site. This is a highly non-trivial proposition since the topological phase of a system is a global property of the whole system emerging from complex interactions between its components, and therefore even defining a local topological signal is a daunting theoretical task. To our knowledge this is the first time that a signal describing the localization of topological information in the bulk of topological condensed matter systems is presented in the literature.

The Shannon information entropy signals presented for the first time in this work provide a clear illustration of how model explainability in machine learning can guide new discoveries in condensed matter and quantum materials physics, since the existence of these signals was established by analyzing data from several thousand SSH systems which, taken individually, could not have provided any concrete hint of their existence. 

\begin{figure}
\centering
\subfigure[]{\label{ssh1}\includegraphics[width=.45\textwidth]{./phase_diagrams/ssh1.png}}\quad
\subfigure[]{\label{ssh2}\includegraphics[width=.45\textwidth]{./phase_diagrams/ssh2.png}}
\caption{Phase diagrams in parameter space. a) SSH model with first-neighbor hoppings $t_1$ and $t_2$. The (red) regions with winding number $W$ = 0 are trivial, while the (blue) regions with winding number $W$ = 1 are topologically non-trivial. b) SSH model with first ($t_1$ and $t_2$) and second ($T_1$ and $T_2$) nearest-neighbor hoppings. In this article we set $t_1$ = $t_2$ = 1 and renamed the variables $T_1$ $\rightarrow$ $t_1$, $T_2$ $\rightarrow$ $t_2$ for convenience. The (orange) region with winding number $W$ = 0 is trivial while the others with winding numbers $W$ = -1, $W$ = 1 and $W$ = 2 (red, green and blue respectively) are topologically non-trivial.}
\label{fig:phasediagrams}
\end{figure}

\section*{Numerical experiments}

The eigenvector ensembling algorithm consists of five steps: 1) Generating Hamiltonians in real space and their corresponding winding numbers; 2) Creating training, validation and test sets; 3) Training on real space eigenvectors of Hamiltonians in the training set; 4) Eigenvector ensembling and 5) Bootstrapping. A detailed description of the algorithm is found in the section \textbf{The eigenvector ensembling algorithm} in the Supplementary Material. Here we present results of the numerical experiments we performed with it. We start with the results from the simplest case, the SSH model with nearest-neighbor hopping (here called SSH 1, figure \ref{ssh1}), then we analize the SSH model with first and second nearest-neighbor hoppings (here called SSH 2, figure \ref{ssh2}).

In each experiment our grid consisted of 6561 Hamiltonians uniformly distributed in the closed square $[-2,2]\times[-2,2]$ in the $t_1$-$t_2$ plane in parameter space. The goal in each experiment is to recover the corresponding phase diagram in 2D (two-dimensional) parameter space, figures \ref{ssh1} and \ref{ssh2}, from local lattice data in the much higher-dimensional real space (100D - in both experiments lattices have 50 unit cells, yielding 100$\times$100 Hamiltonian matrices).

This task is particularly hard near phase transition boundaries, where numerical computation of winding numbers become less stable. For this reason, when sampling the training set we only consider those Hamiltonians in the grid whose numerically computed winding numbers lie in a range $\epsilon = 0.01$ around the allowed winding number values. Therefore, a good performance metric is the accuracy measured at those Hamiltonians near phase transitions that are never used for training, and thus we assign them to the test set. The remaining Hamiltonians in the grid are split into training and validation sets as detailed in the subsections below.

When generating the Hamiltonians we applied periodic boundary conditions to eliminate border effects. This should make recovering a topological signal from local eigenvector coordinates even harder, since in this case the translational symmetry of the systems should allow for no obvious way to distinguish between unit cells. The choice of periodic boundary conditions also implies that the information recovered from real space data comes from the bulk of the topological systems considered and therefore provides strong evidence for the existence of topological signatures in the bulk of such systems. 

Figures \ref{figexp1_exp} and \ref{figexp2_exp} respectively illustrate single iterations of experiments 1 and 2 as seen from parameter space. The accuracy statistics presented in the following subsections and probability heatmaps shown in figures \ref{ssh1_heatmaps} and \ref{ssh2_heatmaps} were obtained after bootstrapping each experiment $n_{exp}$ = 100 times. The recovered probability heatmaps faithfully portray the phase diagrams in figure \ref{fig:phasediagrams}, with clear phase transition lines appearing in the regions of highest uncertainty.

\subsection*{Experiment 1: Learning a first-neighbor hopping SSH model with decision trees}

Our test set in this experiment contained 1005 Hamiltonians (approx. 15.3\% of all data). Of the remaining 5556 Hamiltonians, 556 were randomly assigned to the training set (approx. 8.5\%) and 5000 (approx. 76.2\%) were used to compute validation scores at each iteration. These proportions between training and validation sets are such that approximately 10\%  of Hamiltonians from outside of the test set were used for training at each iteration. The composition of the train + validation set for this experiment was 50.8\% of Hamiltonians with winding number $W$ = 0 and 49.2\% with winding number $W$ = 1. The composition of the test set was 44.8\% of Hamiltonians with winding number $W$ = 0 and 55.2\% with winding number $W=1$. Our algorithm of choice for this experiment was a simple decision tree model \cite{breiman2017classification}.

The bootstrap allows us to collect several statistics to evaluate performance. In particular, we report mean accuracies on training eigenvectors (98.2\%), validation eigenvectors (96.4\%) and test eigenvectors (78.8\%). Eigenvector ensembling substantially improved mean accuracies for Hamiltonians. These were 100\% for training Hamiltonians, 100\% for validation Hamiltonians and 99.1\% for test Hamiltonians.

The probability heatmaps and phase diagram learned by the combination of decision trees with eigenvector ensembling used in experiment 1 are shown in figure \ref{ssh1_heatmaps}.

\begin{figure}
\centering
\subfigure[]{\label{figexp1_exp:a}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/scatter_train_val_test_experiment_0.png}}\quad
\subfigure[]{\label{figexp1_exp:b}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/scatter_winding_train_experiment_0.png}}
\subfigure[]{\label{figexp1_exp:c}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/pcolormesh_prediction_grid_experiment_0.png}}
\caption{Visualization of a single iteration of experiment 1 as seen from 2D parameter space. (a) Train/validation/test split. (b) Distribution of winding numbers in the training set. (c) Phase diagram learned from real space lattice data by a combination of decision tree and eigenvector ensembling.}
\label{figexp1_exp}
\end{figure}

\subsection*{Experiment 2: Learning a first- and second-neighbor hoppings SSH model with random forests}
\label{exp2}

This task is considerably more difficult than the previous one due to the higher number of classes and the fact that some of the labels encompass disconnected regions. For this reason, instead of using a single decision tree, we upgraded our model to a random forest \cite{Breiman2001} with 25 decision trees. Our data set consisted of 1040 (15.8\%) test Hamiltonians. The remaining Hamiltonians are randomly split in half between training and validation sets at each iteration, giving 2761 (42.1\%) training Hamiltonians and 2760 (42.1\%) validation Hamiltonians. The distribution of winding numbers for the Hamiltonians in the train + validation set for this experiment was $W$ = -1 (17.9\%), $W$ = 0 (32.5\%), $W$ = 1 (32.3\%) and $W$ = 2 (17.3\%). The distribution of winding numbers for the Hamiltonians in the test set was $W$ = -1 (36.3\%), $W$ = 0 (11.1\%), $W$ = 1 (12.7\%) and $W$ = 2 (39.9\%).

Mean accuracies across 100 repetitions of experiment 2 were 99.9\% for training eigenvectors, 97.1\% for validation eigenvectors and 66.4\% for test eigenvectors. Mean accuracies resulting from eigenvector ensembling were 100\% for training Hamiltonians, 99.7\% for validation Hamiltonians and 88.2\% for test Hamiltonians. The large accuracy gain achieved by eigenvector ensembling in the test set (going from 66.4\% eigenvector accuracy to 88.2\% Hamiltonian accuracy) attests to its power.

The probability heatmaps and phase diagram learned by the combination of random forests with eigenvector ensembling used in experiment 2 are shown in figure \ref{ssh2_heatmaps}.

\begin{figure}
\centering
\subfigure[]{\label{figexp2_exp:a}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/scatter_train_val_test_experiment_0.png}}\quad
\subfigure[]{\label{figexp2_exp:b}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/scatter_winding_train_experiment_0.png}}
\subfigure[]{\label{figexp2_exp:c}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/pcolormesh_prediction_grid_experiment_0.png}}
\caption{Visualization of a single iteration of experiment 2 as seen from 2D parameter space. (a) Train/validation/test split. (b) Distribution of winding numbers in the training set. (c) Phase diagram learned from real space lattice data by a combination of random forest and eigenvector ensembling.}
\label{figexp2_exp}
\end{figure}

\section*{Information entropy signatures}

We now analyze how the algorithm was able to recover a global property of the Hamiltonians (their topological phase) from bulk local features (real space eigenvector coordinates on each lattice site). Alongside the fact that decision trees and random forests are very easy to train and visualize, the other reason that led us to test our algorithm with them was that they allow us to check which features (and thus which lattice sites) were most informative in training.

The (normalized) relevance of a feature is given by how much it reduces a loss function (e.g. Shannon information entropy or Gini impurity \cite{friedman2001elements}). By averaging normalized relevances as measured by reduction in the information entropy of ensembles of real space eigenvectors across $n_{exp}$ = 100 iterations of both experiment 1 and experiment 2 we recovered Shannon entropy signals that reveal which lattice sites were consistently more relevant in learning topological phases from data in real space for each experiment. These signals are the information entropy signatures of each topological phase transition. 

The bar plots in figure \ref{feature_importances} show how informative each lattice site was in learning topological phases for experiments 1 and 2. They represent the information entropy signatures along the lattices in each SSH system. For experiment 1, only six lattice sites $S_1$ = (0, 1, 3, 50, 51, 53) corresponding to the two sharp peaks seen in figure \ref{feature_importances_ssh1} contributed approximately 70\% of total reduction in Shannon entropy. Similarly, approximately 30\% of total reduction in the Shannon information entropy of eigenvector data from experiment 2 was achieved by eighteen lattice sites $S_2$ = (0, 1, 2, 3, 4, 5, 46, 48, 49, 50, 51, 53, 94, 95, 96, 97, 98, 99) distributed along the three peaks in figure \ref{feature_importances_ssh2}.

Each of the information entropy signatures shown in figure \ref{feature_importances} captures a general pattern that persists regardless of the length of the lattice (i.e, number of unit cells) used to compute them. They are not, therefore, artifacts of particular choices of hyperparameters used to run the eigenvector ensembling algorithm. We present the information entropy signatures for longer lattices in the section \textbf{Information entropy signatures in the macroscopic limit} in the Supplementary Material.

To see if learning the topological phases can be achieved efficiently by employing simpler models we reran experiments 1 and 2 using only a small subset of most relevant lattice sites. In our rerun of experiment 1 using only lattice sites $S'_1$ = (0, 50, 51, 99) (which contributed approximately 45 \% of total reduction in Shannon information entropy in experiment 1), mean accuracies were 97.0\% for training eigenvectors, 91.5\% for validation eigenvectors and 72.8\% for test eigenvectors. Mean accuracies obtained from eigenvector ensembling were 99.1\% for training Hamiltonians, 99.5\% for validation Hamiltonians and 94.5\% for test Hamiltonians.

Mean accuracies for our rerun of experiment 2 using only lattice sites $S'_2$ = (0, 1, 3, 48, 50, 51, 96, 98, 99) (which contributed approximately 20 \% of total reduction in Shannon information entropy in experiment 2) were 99.9\% for training eigenvectors, 87.7\% for validation eigenvectors and 47.3\% for test eigenvectors. Eigenvector ensembling yields mean accuracies of 100\% for training Hamiltonians, 99.5\% for validation Hamiltonians and 74.5\% for test Hamiltonians.  

These results demonstrate that learning topological phases from local real space data in the bulk is still possible even for small subsets of lattice sites. We refer the reader to the section \textbf{Learning topological phases from real space data} in the Supplementary Material for a discussion of how this is possible.

\begin{figure}
\centering
\subfigure[]{\label{ssh1_heatmap_0}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/imshow_winding_grid_winding_0_sim.png}}
\subfigure[]{\label{ssh1_heatmap_1}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/imshow_winding_grid_winding_1_sim.png}}
\subfigure[]{\label{ssh1_heatmap}\includegraphics[width=.32\textwidth]{./ssh1/periodic_100_6561/merge_imshow_winding_grids_second_sim.png}}
\caption{Probability heatmaps learned by a combination of decision trees with eigenvector ensembling from bulk real space eigenvector data in experiment 1. Heatmaps were averaged across all 100 iterations of the experiment. (a) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to 0.  (b) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to 1. (c) The phase diagram resulting from heatmaps (a) and (b).}
\label{ssh1_heatmaps}
\end{figure}

\begin{figure}
\centering
\subfigure[]{\label{ssh2_heatmap_-1}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/imshow_winding_grid_winding_-1_sim.png}}
\subfigure[]{\label{ssh2_heatmap_0}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/imshow_winding_grid_winding_0_sim.png}}
\subfigure[]{\label{ssh2_heatmap_1}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/imshow_winding_grid_winding_1_sim.png}}
\subfigure[]{\label{ssh2_heatmap_2}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/imshow_winding_grid_winding_2_sim.png}}
\subfigure[]{\label{ssh2_heatmap}\includegraphics[width=.32\textwidth]{./ssh2/periodic_100_6561/merge_imshow_winding_grids_sim.png}}
\caption{Probability heatmaps learned by a combination of random forests with eigenvector ensembling from bulk real space eigenvector data in experiment 2. Heatmaps were averaged across all 100 iterations of the experiment. (a) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to -1.  (b) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to 0. (c) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to 1. (d) Probability heatmap showing the probability that a Hamiltonian in the grid has winding number equal to 2. (e) The phase diagram resulting from heatmaps (a)-(d).}
\label{ssh2_heatmaps}
\end{figure}

\section*{Discussion}

Given the increasing complexity of systems studied in condensed matter physics and the rising demand for materials with exotic and robust properties to power future technological progress, it is only expected that data-driven approaches to physics will grow in demand. Our work represents a step in this direction, as we have implemented a data-driven approach to the search for new topological materials bypassing the use of wavevector space data.

The development of data-driven methods based on real space lattice data will be particularly relevant to the study of disordered systems in condensed matter. Such systems usually break translational symmetry and therefore are not amenable to wavevector space methods.

An advantage of using data from real space is that it enables us to investigate how topological information is distributed in the system. This was demonstrated by the information entropy signatures recovered from the Shannon entropy of ensembles of eigenvectors in each experiment. The existence of such signals that can be recovered from data from many distinct physical systems but are hard to conceptualize from sheer theoretical reasoning provides a clear example of how machine learning can be an important tool in the investigation and discovery of new quantum materials.

We should remark on the subtleties of the information entropy signatures presented here. Although they give us a visualization of how important each lattice site was in determining the topological phases of Hamiltonians, these importances actually express a global property of the whole lattice. Therefore, a lattice site that appears unimportant in an information entropy signature plot may not be unimportant or void of topological information by itself. To give a concrete example, reduction in Shannon entropy tends to be distributed among highly correlated variables. This implies that if only a single lattice site in a highly correlated subset is used, it will likely inherit most of the reduction in Shannon entropy from the other correlated lattice sites in the subset. In this regard the information entropy signatures presented here express a summary of relations between lattice sites and are therefore intrinsically global. Furthermore, it should be emphasized that these signals were recovered from the analysis of data from several thousand SSH systems in each experiment and therefore they are not a property of a single SSH lattice. They are rather a pattern that emerges from correlating topological phase with lattice eigenvector data for several SSH systems.   

We performed several tests on the information entropy signatures. By rerunning each experiment with longer lattices (i.e. increasing the number of unit cells) we have verified that the signals in figures \ref{feature_importances_ssh1} and \ref{feature_importances_ssh2} appear to converge to well defined continuous density functions in the macroscopic limit. The macroscopic limit of these information entropy signals may be an important signature of topological systems and thus merits further theoretical investigation. A detailed discussion of this point is presented in the section \textbf{Information entropy signatures in the macroscopic limit} in the Supplementary Material.

Recent works have demonstrated the existence of local topological markers in real space that carry important information on the topological state of a system \cite{PhysRevB.84.241106,caio2019topological}.  Given that topological signals such as the ones shown in figures \ref{feature_importances_ssh1} and \ref{feature_importances_ssh2} are measured in terms of quantities that have actual physical meaning such as Shannon information entropy or Gini impurity, the results presented here suggest a new road for theoretical investigation. Whether there is any relationship between local topological markers and the information entropy of the ensemble of eigenvectors is left for speculation.

The eigenvector ensembling algorithm employed in this work is likely to have further applications in data-driven physics. This is because most of physics is based on eigenvector decomposition, and statistical physics itself can be seen as an application of similar ensembling principles. It is therefore expected that a much broader class of data-driven physics problems could benefit from the techniques described in this paper.

One final comment should be made about the flourishing relationship between physics and machine learning. In this work we have demonstrated how a machine learning approach can provide new insights into complex physical phenomena of current interest. The other direction of this relationship (physics enhancing understanding in machine learning) is equally important. As the need for ever more powerful machine learning algorithms continues to grow, the development of mathematical frameworks for understanding general data spaces (i.e., a physics of data) will be of crucial relevance. This pursuit is seen in many theoretical works investigating the intriguing connections between geometry, topology and data \cite{carlsson2009topology}$^-$\cite{belkin2003problems}. The detailed study of data generated by physical models with non-trivial geometrical and topological properties such as the SSH model may provide invaluable insights into the structure and shape of real world high-dimensional data, since these models usually underscore well known mathematical frameworks behind the data generating process, a feature that is often absent from machine learning applications. Thus, far from being restricted to applications in physics, the study of the topological and geometrical properties of data sets generated by physical models will also be of great value to the machine learning and artificial intelligence communities.  

\begin{figure}
\centering
\subfigure[]{\label{feature_importances_ssh1}\includegraphics[width=0.49\textwidth]{./ssh1/periodic_100_6561/plot_feature_importances.png}}\quad
\subfigure[]{\label{feature_importances_ssh2}\includegraphics[width=0.49\textwidth]{./ssh2/periodic_100_6561/plot_feature_importances.png}}\quad
\caption{Information entropy signatures of the topological phase transitions from experiments 1 and 2. (a) In experiment 1, the two sharp peaks in the Shannon entropy signal account for approximately 70\% of reduction in information entropy. These two peaks correspond to the lattice sites $S_1$. (b) In experiment 2, the three visible peaks account for approximately 30\% of reduction in information entropy. These three peaks are located along lattice sites $S_2$.}
\label{feature_importances}
\end{figure}

\begin{thebibliography}{10}

\bibitem{RevModPhys.82.3045}
M.~Z. Hasan and C.~L. Kane, ``Colloquium: Topological insulators,'' {\em Rev.
  Mod. Phys.}, vol.~82, pp.~3045--3067, Nov 2010.

\bibitem{CONTINENTINO2017A1}
M.~A. Continentino, ``Topological phase transitions,'' {\em Physica B:
  Condensed Matter}, vol.~505, pp.~A1 -- A2, 2017.

\bibitem{PhysRevB.95.094509}
T.~O. Puel, P.~D. Sacramento, and M.~A. Continentino, ``$4\ensuremath{\pi}$
  josephson currents in junctions of hybridized multiband superconductors,''
  {\em Phys. Rev. B}, vol.~95, p.~094509, Mar 2017.

\bibitem{PhysRevE.97.012107}
M.~A. Griffith and M.~A. Continentino, ``Casimir amplitudes in topological
  quantum phase transitions,'' {\em Phys. Rev. E}, vol.~97, p.~012107, Jan
  2018.

\bibitem{ryu2010topological}
S.~Ryu, A.~P. Schnyder, A.~Furusaki, and A.~W. Ludwig, ``Topological insulators
  and superconductors: tenfold way and dimensional hierarchy,'' {\em New
  Journal of Physics}, vol.~12, no.~6, p.~065010, 2010.

\bibitem{atala2013direct}
M.~Atala, M.~Aidelsburger, J.~T. Barreiro, D.~Abanin, T.~Kitagawa, E.~Demler,
  and I.~Bloch, ``Direct measurement of the zak phase in topological bloch
  bands,'' {\em Nature Physics}, vol.~9, no.~12, p.~795, 2013.

\bibitem{Stuhl1514}
B.~K. Stuhl, H.-I. Lu, L.~M. Aycock, D.~Genkina, and I.~B. Spielman,
  ``Visualizing edge states with an atomic bose gas in the quantum hall
  regime,'' {\em Science}, vol.~349, no.~6255, pp.~1514--1518, 2015.

\bibitem{leder2016real}
M.~Leder, C.~Grossert, L.~Sitta, M.~Genske, A.~Rosch, and M.~Weitz,
  ``Real-space imaging of a topologically protected edge state with ultracold
  atoms in an amplitude-chirped optical lattice,'' {\em Nature communications},
  vol.~7, p.~13112, 2016.

\bibitem{goldman2016topological}
N.~Goldman, J.~Budich, and P.~Zoller, ``Topological quantum matter with
  ultracold gases in optical lattices,'' {\em Nature Physics}, vol.~12, no.~7,
  p.~639, 2016.

\bibitem{meier2016observation}
E.~J. Meier, F.~A. An, and B.~Gadway, ``Observation of the topological soliton
  state in the su--schrieffer--heeger model,'' {\em Nature communications},
  vol.~7, p.~13986, 2016.

\bibitem{hafezi2013imaging}
M.~Hafezi, S.~Mittal, J.~Fan, A.~Migdall, and J.~Taylor, ``Imaging topological
  edge states in silicon photonics,'' {\em Nature Photonics}, vol.~7, no.~12,
  p.~1001, 2013.

\bibitem{rechtsman2013photonic}
M.~C. Rechtsman, J.~M. Zeuner, Y.~Plotnik, Y.~Lumer, D.~Podolsky, F.~Dreisow,
  S.~Nolte, M.~Segev, and A.~Szameit, ``Photonic floquet topological
  insulators,'' {\em Nature}, vol.~496, no.~7444, p.~196, 2013.

\bibitem{lu2016topological}
L.~Lu, J.~D. Joannopoulos, and M.~Solja{\v{c}}i{\'c}, ``Topological states in
  photonic systems,'' {\em Nature Physics}, vol.~12, no.~7, p.~626, 2016.

\bibitem{PhysRevX.5.031011}
V.~Peano, C.~Brendel, M.~Schmidt, and F.~Marquardt, ``Topological phases of
  sound and light,'' {\em Phys. Rev. X}, vol.~5, p.~031011, Jul 2015.

\bibitem{peng2016experimental}
Y.-G. Peng, C.-Z. Qin, D.-G. Zhao, Y.-X. Shen, X.-Y. Xu, M.~Bao, H.~Jia, and
  X.-F. Zhu, ``Experimental demonstration of anomalous floquet topological
  insulator for sound,'' {\em Nature communications}, vol.~7, p.~13368, 2016.

\bibitem{kitagawa2012observation}
T.~Kitagawa, M.~A. Broome, A.~Fedrizzi, M.~S. Rudner, E.~Berg, I.~Kassal,
  A.~Aspuru-Guzik, E.~Demler, and A.~G. White, ``Observation of topologically
  protected bound states in photonic quantum walks,'' {\em Nature
  communications}, vol.~3, p.~882, 2012.

\bibitem{cardano2016statistical}
F.~Cardano, M.~Maffei, F.~Massa, B.~Piccirillo, C.~De~Lisio, G.~De~Filippis,
  V.~Cataudella, E.~Santamato, and L.~Marrucci, ``Statistical moments of
  quantum-walk dynamics reveal topological quantum transitions,'' {\em Nature
  communications}, vol.~7, p.~11439, 2016.

\bibitem{PhysRevX.7.031023}
E.~Flurin, V.~V. Ramasesh, S.~Hacohen-Gourgy, L.~S. Martin, N.~Y. Yao, and
  I.~Siddiqi, ``Observing topological invariants using quantum walks in
  superconducting circuits,'' {\em Phys. Rev. X}, vol.~7, p.~031023, Aug 2017.

\bibitem{soluyanov2015type}
A.~A. Soluyanov, D.~Gresch, Z.~Wang, Q.~Wu, M.~Troyer, X.~Dai, and B.~A.
  Bernevig, ``Type-ii weyl semimetals,'' {\em Nature}, vol.~527, no.~7579,
  p.~495, 2015.

\bibitem{PhysRevX.5.031013}
B.~Q. Lv, H.~M. Weng, B.~B. Fu, X.~P. Wang, H.~Miao, J.~Ma, P.~Richard, X.~C.
  Huang, L.~X. Zhao, G.~F. Chen, Z.~Fang, X.~Dai, T.~Qian, and H.~Ding,
  ``Experimental discovery of weyl semimetal taas,'' {\em Phys. Rev. X},
  vol.~5, p.~031013, Jul 2015.

\bibitem{PhysRevLett.42.1698}
W.~P. Su, J.~R. Schrieffer, and A.~J. Heeger, ``Solitons in polyacetylene,''
  {\em Phys. Rev. Lett.}, vol.~42, pp.~1698--1701, Jun 1979.

\bibitem{maffei2018topological}
M.~Maffei, A.~Dauphin, F.~Cardano, M.~Lewenstein, and P.~Massignan,
  ``Topological characterization of chiral models through their long time
  dynamics,'' {\em New Journal of Physics}, vol.~20, no.~1, p.~013023, 2018.

\bibitem{RevModPhys.73.681}
A.~J. Heeger, ``Nobel lecture: Semiconducting and metallic polymers: The fourth
  generation of polymeric materials,'' {\em Rev. Mod. Phys.}, vol.~73,
  pp.~681--700, Sep 2001.

\bibitem{kane2014topological}
C.~Kane and T.~Lubensky, ``Topological boundary modes in isostatic lattices,''
  {\em Nature Physics}, vol.~10, no.~1, p.~39, 2014.

\bibitem{Chen13004}
B.~G.-g. Chen, N.~Upadhyaya, and V.~Vitelli, ``Nonlinear conduction via
  solitons in a topological mechanical insulator,'' {\em Proceedings of the
  National Academy of Sciences}, vol.~111, no.~36, pp.~13004--13009, 2014.

\bibitem{carrasquilla2017machine}
J.~Carrasquilla and R.~G. Melko, ``Machine learning phases of matter,'' {\em
  Nature Physics}, vol.~13, no.~5, p.~431, 2017.

\bibitem{PhysRevX.7.031038}
K.~Ch'ng, J.~Carrasquilla, R.~G. Melko, and E.~Khatami, ``Machine learning
  phases of strongly correlated fermions,'' {\em Phys. Rev. X}, vol.~7,
  p.~031038, Aug 2017.

\bibitem{PhysRevB.94.195105}
L.~Wang, ``Discovering phase transitions with unsupervised learning,'' {\em
  Phys. Rev. B}, vol.~94, p.~195105, Nov 2016.

\bibitem{broecker2017machine}
P.~Broecker, J.~Carrasquilla, R.~G. Melko, and S.~Trebst, ``Machine learning
  quantum phases of matter beyond the fermion sign problem,'' {\em Scientific
  reports}, vol.~7, no.~1, p.~8823, 2017.

\bibitem{van2017learning}
E.~P. Van~Nieuwenburg, Y.-H. Liu, and S.~D. Huber, ``Learning phase transitions
  by confusion,'' {\em Nature Physics}, vol.~13, no.~5, p.~435, 2017.

\bibitem{PhysRevLett.120.066401}
P.~Zhang, H.~Shen, and H.~Zhai, ``Machine learning topological invariants with
  neural networks,'' {\em Phys. Rev. Lett.}, vol.~120, p.~066401, Feb 2018.

\bibitem{PhysRevB.98.085402}
N.~Sun, J.~Yi, P.~Zhang, H.~Shen, and H.~Zhai, ``Deep learning topological
  invariants of band insulators,'' {\em Phys. Rev. B}, vol.~98, p.~085402, Aug
  2018.

\bibitem{PhysRevB.97.174435}
P.~Suchsland and S.~Wessel, ``Parameter diagnostics of phases and phase
  transition learning by neural networks,'' {\em Phys. Rev. B}, vol.~97,
  p.~174435, May 2018.

\bibitem{PhysRevLett.120.257204}
J.~Venderley, V.~Khemani, and E.-A. Kim, ``Machine learning out-of-equilibrium
  phases of matter,'' {\em Phys. Rev. Lett.}, vol.~120, p.~257204, Jun 2018.

\bibitem{PhysRevB.97.205110}
N.~Yoshioka, Y.~Akagi, and H.~Katsura, ``Learning disordered topological phases
  by statistical recovery of symmetry,'' {\em Phys. Rev. B}, vol.~97,
  p.~205110, May 2018.

\bibitem{PhysRevB.96.195145}
D.-L. Deng, X.~Li, and S.~Das~Sarma, ``Machine learning topological states,''
  {\em Phys. Rev. B}, vol.~96, p.~195145, Nov 2017.

\bibitem{PhysRevB.97.134109}
P.~Huembeli, A.~Dauphin, and P.~Wittek, ``Identifying quantum phase transitions
  with adversarial neural networks,'' {\em Phys. Rev. B}, vol.~97, p.~134109,
  Apr 2018.

\bibitem{PhysRevB.97.115453}
D.~Carvalho, N.~A. Garc\'{\i}a-Mart\'{\i}nez, J.~L. Lado, and
  J.~Fern\'andez-Rossier, ``Real-space mapping of topological invariants using
  artificial neural networks,'' {\em Phys. Rev. B}, vol.~97, p.~115453, Mar
  2018.

\bibitem{PhysRevB.96.245119}
Y.~Zhang, R.~G. Melko, and E.-A. Kim, ``Machine learning ${\mathbb{z}}_{2}$
  quantum spin liquids with quasiparticle statistics,'' {\em Phys. Rev. B},
  vol.~96, p.~245119, Dec 2017.

\bibitem{rodriguez2018identifying}
J.~F. Rodriguez-Nieva and M.~S. Scheurer, ``Identifying topological order via
  unsupervised machine learning,'' {\em arXiv preprint arXiv:1805.05961}, 2018.

\bibitem{breiman2017classification}
L.~Breiman, J.~Friedman, C.~J. Stone, and R.~A. Olshen, {\em Classification and
  regression trees}.
\newblock Chapman and Hall/CRC, 1984.

\bibitem{Breiman2001}
L.~Breiman, ``Random forests,'' {\em Machine Learning}, vol.~45, pp.~5--32, Oct
  2001.

\bibitem{friedman2001elements}
J.~Friedman, T.~Hastie, and R.~Tibshirani, {\em The elements of statistical
  learning}.
\newblock Springer New York, NY, USA:, 2001.

\bibitem{PhysRevB.84.241106}
R.~Bianco and R.~Resta, ``Mapping topological order in coordinate space,'' {\em
  Phys. Rev. B}, vol.~84, p.~241106, Dec 2011.

\bibitem{caio2019topological}
M.~D. Caio, G.~M{\"o}ller, N.~R. Cooper, and M.~Bhaseen, ``Topological marker
  currents in chern insulators,'' {\em Nature Physics}, p.~1, 2019.

\bibitem{carlsson2009topology}
G.~Carlsson, ``Topology and data,'' {\em Bulletin of the American Mathematical
  Society}, vol.~46, no.~2, pp.~255--308, 2009.

\bibitem{wasserman2018topological}
L.~Wasserman, ``Topological data analysis,'' {\em Annual Review of Statistics
  and Its Application}, vol.~5, pp.~501--532, 2018.

\bibitem{wang2005adaptive}
J.~Wang, Z.~Zhang, and H.~Zha, ``Adaptive manifold learning,'' in {\em Advances
  in neural information processing systems}, pp.~1473--1480, 2005.

\bibitem{lin2008riemannian}
T.~Lin and H.~Zha, ``Riemannian manifold learning,'' {\em IEEE Transactions on
  Pattern Analysis and Machine Intelligence}, vol.~30, no.~5, pp.~796--809,
  2008.

\bibitem{belkin2003problems}
M.~Belkin, {\em Problems of learning on manifolds}.
\newblock The University of Chicago, 2003.

\end{thebibliography}

\section*{Acknowledgements}

We thank S. E. Rowley, J. F. de Oliveira, T. Micklitz and M. A. Continentino for insightful discussions and S. E. Rowley for carefully reading the manuscript and suggesting improvements. N. L. Holanda acknowledges financial support from CENPES/Petrobr\'as/CBPF. M. A. R. Griffith acknowledges financial support from Capes. N. L. Holanda is grateful to the Theory of Condensed Matter and Quantum Materials groups at the Cavendish Laboratory and the Quantum Information Group at CBPF.


\section*{Author contributions}

Both authors of this work contributed equally to its realization at all stages.

\section*{Competing financial interests}

The authors declare no competing financial or non-financial interests.

\section*{Additional information}

Correspondence and requests for materials should be addressed to N. L. Holanda. The source code used to run simulations is available on \href{https://github.com/linneuholanda/ml_topological_phases_in_real_space}{Github}.


%\newpage
%\bibliographystylesupp{ieeetr}
%\bibliographysupp{supp}


\end{document}
